import os
from config import *
from torch import nn
from scipy.ndimage.filters import gaussian_filter1d
from torch.autograd import Variable
import torch
import numpy as np
import eval_utils as utils
import re
from tqdm import tqdm

def read_data(inputFile):
    filesAsStrings = []
    # Load entries from txt file:
    with open(input, "r") as file:
        curFile = read_next_entry(file)
        while curFile != None:
            # Process the file
            curFile = read_next_entry(file)
            if curFile == None:
                break
            filesAsStrings.append(curFile)

    print("Finished processing files")

    # File is empty - return None
    if len(filesAsStrings) == 0:
        print("ERROR: No files found - check \"%s\" file" % (inputFile))
        return None
    
    return filesAsStrings

def read_next_entry(file):
    # with bininja processed txt file, we can now create embeddings
    curFile = []
    line = read_next_line(file)
    if line == None:
        if len(curFile) > 0:
            "".join(curFile)
            return curFile
        else:
            return None
    #check for end of file text (when we see lines like 12/55 new file starting)
    if re.search(r"^[0-9]*\/[0-9]*", line) != None:
        curFile.append(line)
    else:
        "".join(curFile)
    return curFile

def read_next_line(file):
    line = file.readline()
    if not line:
        return None
    return line

def get_entry_count(inputFile):
    #use grep to get lines with the format "i/# of entries" (indicating a new file)
    grepCall = os.subprocess.call(["grep", "-n", "^[0-9]*\/[0-9]*", inputFile, ">", "tmpOut.txt"])
    if grepCall.returncode != 0:
        print("ERROR: grep command failed - return code %d" % (grepCall.returncode))
        return None
    # Get the number of lines in the file
    with open("tmpOut.txt", "r") as file:
        lineCount = len(file.readlines())
    return lineCount

def setMaxEmbeddingSize(maxEmbeddingSize):
    with open("maxEmbeddingSize.txt", "w") as file:
        file.write(str(maxEmbeddingSize))
 
def create_embeddings(model_path, vocab_path):
    maxEmbeddingSize = 0
    inputFile = "./bininja_processed.txt"
    # Load the model
    palmtree = utils.UsableTransformer(model_path=model_path, vocab_path=vocab_path)

    data = read_data(inputFile)
    embeddings = []
    if data == None:
        print("ERROR: No data found!")
        return
    for i in tqdm(range(len(data))):
        # Get the embeddings for the file
        embedding = palmtree.encode(data[i])
        if embedding.shape[0] > maxEmbeddingSize:
            maxEmbeddingSize = len(embedding)
        # Save the embeddings to a file
        np.save("./embeddings/embedding_" + str(i) + ".npy", embeddings)
    # Save the max embedding size to a file; just makes things easier later on
    setMaxEmbeddingSize(maxEmbeddingSize)

    

def main():
    model_path = "./palmtree/transformer.ep19"
    vocab_path = "./palmtree/vocab"

    create_embeddings(model_path, vocab_path)